{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition as fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imutils in c:\\users\\sony\\anaconda\\envs\\virtual\\lib\\site-packages (0.5.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the input image and show its dimensions, keeping in mind that\n",
    "# images are represented as a multi-dimensional NumPy array with\n",
    "# shape no. rows (height) x no. columns (width) x no. channels (depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(r\"C:\\Users\\Sony\\Desktop\\jp.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "(h, w, d) = image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "width=600, height=322, depth=3\n"
     ]
    }
   ],
   "source": [
    "print(\"width={}, height={}, depth={}\".format(w, h, d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the image to our screen -- we will need to click the window\n",
    "# open by OpenCV and press a key on our keyboard to continue execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Image\", image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R=41, G=49, B=37\n"
     ]
    }
   ],
   "source": [
    "# access the RGB pixel located at x=50, y=100, keepind in mind that\n",
    "# OpenCV stores images in BGR order rather than RGB\n",
    "(B, G, R) = image[100, 50]\n",
    "print(\"R={}, G={}, B={}\".format(R, G, B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract a 100x100 pixel square ROI (Region of Interest) from the\n",
    "# input image starting at x=320,y=60 at ending at x=420,y=160\n",
    "roi = image[60:160, 320:420]\n",
    "cv2.imshow(\"ROI\", roi)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# resize the image to 200x200px, ignoring aspect ratio\n",
    "resized = cv2.resize(image, (200, 200))\n",
    "cv2.imshow(\"Fixed Resizing\", resized)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fixed resizing and distort aspect ratio so let's resize the width\n",
    "# to be 300px but compute the new height based on the aspect ratio\n",
    "r = 300.0 / w\n",
    "dim = (300, int(h * r))\n",
    "resized = cv2.resize(image, dim)\n",
    "cv2.imshow(\"Aspect Ratio Resize\", resized)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# manually computing the aspect ratio can be a pain so let's use the\n",
    "# imutils library instead\n",
    "resized = imutils.resize(image, width=300)\n",
    "cv2.imshow(\"Imutils Resize\", resized)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's rotate an image 45 degrees clockwise using OpenCV by first\n",
    "# computing the image center, then constructing the rotation matrix,\n",
    "# and then finally applying the affine warp\n",
    "center = (w // 2, h // 2)\n",
    "M = cv2.getRotationMatrix2D(center, -45, 1.0)\n",
    "rotated = cv2.warpAffine(image, M, (w, h))\n",
    "cv2.imshow(\"OpenCV Rotation\", rotated)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rotation can also be easily accomplished via imutils with less code\n",
    "rotated = imutils.rotate(image, -45)\n",
    "cv2.imshow(\"Imutils Rotation\", rotated)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OpenCV doesn't \"care\" if our rotated image is clipped after rotation\n",
    "# so we can instead use another imutils convenience function to help\n",
    "# us out\n",
    "rotated = imutils.rotate_bound(image, 45)\n",
    "cv2.imshow(\"Imutils Bound Rotation\", rotated)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply a Gaussian blur with a 11x11 kernel to the image to smooth it,\n",
    "# useful when reducing high frequency noise\n",
    "blurred = cv2.GaussianBlur(image, (11, 11), 0)\n",
    "cv2.imshow(\"Blurred\", blurred)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# draw a 2px thick red rectangle surrounding the face\n",
    "output = image.copy()\n",
    "cv2.rectangle(output, (320, 60), (420, 160), (0, 0, 255), 2)\n",
    "cv2.imshow(\"Rectangle\", output)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# draw a blue 20px (filled in) circle on the image centered at\n",
    "# x=300,y=150\n",
    "output = image.copy()\n",
    "cv2.circle(output, (300, 150), 20, (255, 0, 0), -1)\n",
    "cv2.imshow(\"Circle\", output)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# draw a 5px thick red line from x=60,y=20 to x=400,y=200\n",
    "output = image.copy()\n",
    "cv2.line(output, (60, 20), (400, 200), (0, 0, 255), 5)\n",
    "cv2.imshow(\"Line\", output)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# draw green text on the image\n",
    "output = image.copy()\n",
    "cv2.putText(output, \"OpenCV + Jurassic Park!!!\", (10, 25), \n",
    "\tcv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "cv2.imshow(\"Text\", output)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] -i IMAGE\n",
      "ipykernel_launcher.py: error: the following arguments are required: -i/--image\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "import argparse\n",
    "import imutils\n",
    "import cv2\n",
    "# construct the argument parser and parse the arguments\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-i\", \"--image\", required=True,help=\"path to input image\")\n",
    "args = vars(ap.parse_args())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(r\"C:\\Users\\Sony\\Desktop\\tetris_blocks.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "(h, w, d) = image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imshow(\"Image\", image)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert the image to grayscale\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow(\"Gray\", gray)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# applying edge detection we can find the outlines of objects in\n",
    "# images\n",
    "edged = cv2.Canny(gray, 30, 150)\n",
    "cv2.imshow(\"Edged\", edged)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# threshold the image by setting all pixel values less than 225\n",
    "# to 255 (white; foreground) and all pixel values >= 225 to 255\n",
    "# (black; background), thereby segmenting the image\n",
    "thresh = cv2.threshold(gray, 225, 255, cv2.THRESH_BINARY_INV)[1]\n",
    "cv2.imshow(\"Thresh\", thresh)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find contours (i.e., outlines) of the foreground objects in the\n",
    "# thresholded image\n",
    "cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL,\n",
    "\tcv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts = imutils.grab_contours(cnts)\n",
    "output = image.copy()\n",
    "# loop over the contours\n",
    "for c in cnts:\n",
    "\t# draw each contour on the output image with a 3px thick purple\n",
    "\t# outline, then display the output contours one at a time\n",
    "\tcv2.drawContours(output, [c], -1, (240, 0, 159), 3)\n",
    "\tcv2.imshow(\"Contours\", output)\n",
    "\tcv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# draw the total number of contours found in purple\n",
    "text = \"I found {} objects!\".format(len(cnts))\n",
    "cv2.putText(output, text, (10, 25),  cv2.FONT_HERSHEY_SIMPLEX, 0.7,\n",
    "\t(240, 0, 159), 2)\n",
    "cv2.imshow(\"Contours\", output)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we apply erosions to reduce the size of foreground objects\n",
    "mask = thresh.copy()\n",
    "mask = cv2.erode(mask, None, iterations=5)\n",
    "cv2.imshow(\"Eroded\", mask)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# similarly, dilations can increase the size of the ground objects\n",
    "mask = thresh.copy()\n",
    "mask = cv2.dilate(mask, None, iterations=5)\n",
    "cv2.imshow(\"Dilated\", mask)\n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a typical operation we may want to apply is to take our mask and\n",
    "# apply a bitwise AND to our input image, keeping only the masked\n",
    "# regions\n",
    "mask = thresh.copy()\n",
    "output = cv2.bitwise_and(image, image, mask=mask)\n",
    "cv2.imshow(\"Output\", output)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
